{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA Sequencing With Machine Learning\n",
    "\n",
    "In this notebook, I will apply a classification model that can predict a gene's function based on the DNA sequence of the coding sequence alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  class\n",
       "0  ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...      4\n",
       "1  ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...      4\n",
       "2  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "3  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "4  ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data = pd.read_table('human_data.txt')\n",
    "human_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have some data for human DNA sequence coding regions and a class label.  We also have data for Chimpanzee and a more divergent species, the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGCCACAGCTAGATACATCCACCTGATTTATTATAATCTTTTCAA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGAACGAAAATCTATTCGCTTCTTTCGCTGCCCCCTCAATAATAG...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATGGAAACACCCTTCTACGGCGATGAGGCGCTGAGCGGCCTGGGCG...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGTGCACTAAAATGGAACAGCCCTTCTACCACGACGACTCATACG...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATGAGCCGGCAGCTAAACAGAAGCCAGAACTGCTCCTTCAGTGACG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  class\n",
       "0  ATGCCACAGCTAGATACATCCACCTGATTTATTATAATCTTTTCAA...      4\n",
       "1  ATGAACGAAAATCTATTCGCTTCTTTCGCTGCCCCCTCAATAATAG...      4\n",
       "2  ATGGAAACACCCTTCTACGGCGATGAGGCGCTGAGCGGCCTGGGCG...      6\n",
       "3  ATGTGCACTAAAATGGAACAGCCCTTCTACCACGACGACTCATACG...      6\n",
       "4  ATGAGCCGGCAGCTAAACAGAAGCCAGAACTGCTCCTTCAGTGACG...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chimp_data = pd.read_table('chimp_data.txt')\n",
    "dog_data = pd.read_table('dog_data.txt')\n",
    "chimp_data.head()\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the definitions for each of the 7 classes and how many there are in the human training data.  They are gene sequence function groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"Capture1.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating DNA sequence as a \"language\", otherwise known as  k-mer counting\n",
    "\n",
    "A challenge that remains is that none of these above methods results in vectors of uniform length, and that is a requirement for feeding data to a classification or regression algorithm. So with the above methods you have to resort to things like truncating sequences or padding with \"n\" or \"0\" to get vectors of uniform length.\n",
    "\n",
    "DNA and protein sequences can be viewed metaphorically as the language of life. The language encodes instructions as well as function for the molecules that are found in all life forms. The sequence language analogy continues with the genome as the book, subsequences (genes and gene families) are sentences and chapters, k-mers and peptides (motifs) are words, and nucleotide bases and amino acids are the alphabet. Since the analogy seems so apt, it stands to reason that the amazing work done in the natural language processing field should also apply to the natural language of DNA and protein sequences.\n",
    "\n",
    "The method I use here is simple and easy. I first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if I use \"words\" of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
    "\n",
    "Here I am using hexamer “words” but that is arbitrary and word length can be tuned to suit the particular situation. The word length and amount of overlap need to be determined empirically for any given application.\n",
    "\n",
    "In genomics, we refer to these types of manipulations as \"k-mer counting\", or counting the occurances of each possible k-mer sequence. There are specialized tools for this, but the Python natural language processing tools make it supe easy.\n",
    "\n",
    "Here is a function that can be used to convert any sequence (string) to overlapping k-mer words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a function to collect all possible overlapping k-mers of a specified length from any sequence string. We will basically apply the k-mers to the complete sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size=5):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can convert our training data sequences into short overlapping  k-mers of legth 6.  Lets do that for each species of data we have using our getKmers function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['words'] = human_data.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "human_data = human_data.drop('sequence', axis=1)\n",
    "chimp_data['words'] = chimp_data.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "chimp_data = chimp_data.drop('sequence', axis=1)\n",
    "dog_data['words'] = dog_data.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "dog_data = dog_data.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, our coding sequence data is changed to lowercase, split up into all possible k-mer words of length 6 and ready for the next step.  Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgcc, tgccc, gcccc, cccca, cccaa, ccaac, caa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgaa, tgaac, gaacg, aacga, acgaa, cgaaa, gaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtg, tgtgt, gtgtg, tgtgg, gtggc, tggca, ggc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtg, tgtgt, gtgtg, tgtgg, gtggc, tggca, ggc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgca, tgcaa, gcaac, caaca, aacag, acagc, cag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              words\n",
       "0      4  [atgcc, tgccc, gcccc, cccca, cccaa, ccaac, caa...\n",
       "1      4  [atgaa, tgaac, gaacg, aacga, acgaa, cgaaa, gaa...\n",
       "2      3  [atgtg, tgtgt, gtgtg, tgtgg, gtggc, tggca, ggc...\n",
       "3      3  [atgtg, tgtgt, gtgtg, tgtgg, gtggc, tggca, ggc...\n",
       "4      3  [atgca, tgcaa, gcaac, caaca, aacag, acagc, cag..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use.  We can also make a y variable to hold the class labels.  Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_texts = list(human_data['words'])\n",
    "for item in range(len(human_texts)):\n",
    "    human_texts[item] = ' '.join(human_texts[item])\n",
    "y_data = human_data.iloc[:, 0].values                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atgtg tgtgt gtgtg tgtgg gtggc tggca ggcat gcatt cattt atttg tttgg ttggg tgggc gggcg ggcgc gcgct cgctg gctgt ctgtt tgttt gtttg tttgg ttggc tggca ggcag gcagt cagtg agtga gtgat tgatg gatga atgat tgatt gattg attgc ttgcc tgcct gcctt ccttt ctttc tttct ttctg tctgt ctgtt tgttc gttca ttcag tcagt cagtg agtgt gtgtc tgtct gtctg tctga ctgag tgagt gagtg agtgc gtgct tgcta gctat ctatg tatga atgaa tgaag gaaga aagat agatt gattg attgc ttgca tgcac gcaca cacac acaca cacag acaga cagag agagg gaggt aggtc ggtcc gtcca tccag ccaga cagat agatg gatgc atgca tgcat gcatt cattc attcc ttccg tccgt ccgtt cgttt gtttt ttttg tttga ttgag tgaga gagaa agaat gaatg aatgt atgtc tgtca gtcaa tcaat caatg aatgg atgga tggat ggata gatac ataca tacac acacc cacca accaa ccaac caact aactg actgc ctgct tgctg gctgc ctgct tgctt gcttt ctttg tttgg ttgga tggat ggatt gattt atttc tttca ttcac tcacc caccg accgg ccggt cggtt ggttg gttgg ttggc tggcg ggcgg gcggt cggta ggtag gtagt tagtt agttg gttga ttgac tgacc gaccc acccg cccgc ccgct cgctg gctgt ctgtt tgttt gtttg tttgg ttgga tggaa ggaat gaatg aatgc atgca tgcag gcagc cagcc agcca gccaa ccaat caatt aattc attcg ttcga tcgag cgagt gagtg agtga gtgaa tgaag gaaga aagaa agaaa gaaat aaata aatat atatc tatcc atccg tccgt ccgta cgtat gtatt tattt atttg tttgt ttgtg tgtgg gtggc tggct ggctc gctct ctctg tctgt ctgtt tgtta gttac ttaca tacaa acaat caatg aatgg atggt tggtg ggtga gtgaa tgaaa gaaat aaatc aatct atcta tctac ctaca tacaa acaac caacc aacca accat ccata cataa ataag taaga aagaa agaag gaaga aagat agatg gatgc atgca tgcaa gcaac caaca aacag acagc cagca agcat gcatt cattt atttt ttttg tttga ttgaa tgaat gaatt aattt atttg tttga ttgaa tgaat gaata aatac atacc tacca accag ccaga cagac agacc gacca accaa ccaaa caaag aaagt aagtg agtgg gtgga tggat ggatg gatgg atggt tggtg ggtga gtgag tgaga gagat agata gataa ataat taatc aatcc atcct tcctt ccttc cttca ttcat tcatc catct atctt tcttt cttta tttat ttatg tatga atgac tgaca gacaa acaaa caaag aaagg aagga aggag ggagg gagga aggaa ggaat gaatt aattg attga ttgag tgagc gagca agcaa gcaaa caaac aaaca aacaa acaat caatt aattt atttg tttgt ttgta tgtat gtatg tatgt atgtt tgttg gttgg ttgga tggat ggatg gatgg atggt tggtg ggtgt gtgtg tgtgt gtgtt tgttt gtttg tttgc ttgca tgcat gcatt cattt atttg tttgt ttgtt tgttt gtttt tttta tttac ttact tactg actgg ctgga tggat ggata gatac atact tactg actgc ctgcc tgcca gccaa ccaat caata aataa ataag taaga aagaa agaaa gaaag aaagt aagtg agtgt gtgtt tgttc gttcc ttcct tcctg cctgg ctggg tgggt gggta ggtag gtaga tagag agaga gagat agata gatac ataca tacat acata catat atatg tatgg atgga tggag ggagt gagtc agtca gtcag tcaga cagac agacc gacct acctt ccttt ctttg tttgt ttgtt tgttt gttta tttaa ttaaa taaag aaagc aagca agcaa gcaat caatg aatga atgac tgaca gacag acaga cagaa agaag gaaga aagat agatg gatgg atgga tggat ggatt gattt atttt ttttt ttttg tttgg ttggc tggct ggctg gctgt ctgta tgtat gtatg tatgt atgtt tgttc gttca ttcag tcaga cagaa agaag gaagc aagct agcta gctaa ctaaa taaag aaagg aaggt aggtc ggtct gtctt tcttg cttgt ttgtt tgtta gttac ttaca tacat acatt cattg attga ttgaa tgaag gaagc aagca agcac gcact cactc actcc ctccg tccgc ccgcg cgcga gcgac cgact gactc actcc ctccc tccct ccctt ccttt ctttt ttttt tttta tttaa ttaaa taaaa aaaag aaagt aagtg agtgg gtgga tggag ggagc gagcc agcct gcctt ccttt ctttt ttttc tttct ttctt tcttc cttcc ttcct tcctg cctgg ctgga tggac ggaca gacac acact cacta actat ctatg tatga atgaa tgaag gaagt aagtt agttt gtttt ttttg tttgg ttgga tggat ggatt gattt attta tttaa ttaaa taaag aaagc aagcc agcca gccaa ccaaa caaat aaatg aatgg atggc tggca ggcaa gcaaa caaag aaagt aagtt agttg gttgc ttgca tgcat gcatc catcc atccg tccgt ccgtg cgtgg gtgga tggaa ggaaa gaaat aaatg aatgg atggt tggtt ggtta gttaa ttaaa taaat aaata aatat atatc tatca atcat tcatc catca atcac tcact cactg actgt ctgtc tgtcg gtcgg tcggg cggga gggat ggatg gatgt atgta tgtac gtacc taccc acccc cccct ccctg cctgc ctgca tgcac gcacg cacgc acgcc cgccc gccct ccctc cctct ctcta tctat ctatg tatga atgac tgaca gacaa acaat caatg aatgt atgtg tgtgg gtgga tggag ggaga gagaa agaaa gaaac aaact aactc actct ctctt tcttt ctttc tttcc ttcca tccag ccagg caggt aggtt ggttt gtttt ttttg tttga ttgag tgaga gagat agata gatag ataga tagaa agaaa gaaac aaact aactg actgt ctgtg tgtga gtgaa tgaag gaaga aagaa agaac gaaca aacaa acaac caacc aacct acctc cctca ctcag tcagg cagga aggat ggatc gatcc atcct tcctt ccttt ctttt ttttt tttta tttaa ttaat taata aataa ataat taatg aatgc atgct tgctg gctgt ctgta tgtaa gtaaa taaag aaaga aagaa agaaa gaaac aaacg aacgt acgtt cgttt gtttg tttga ttgat tgatg gatga atgac tgaca gacag acaga cagac agaca gacag acaga cagaa agaag gaagg aagga aggat ggatt gattg attgg ttggc tggct ggctg gctgc ctgcc tgcct gcctt ccttt ctttt tttta tttat ttatc tatca atcag tcagg caggg agggg ggggg ggggc gggct ggctt gcttg cttgg ttgga tggac ggact gactc actcc ctcca tccag ccagc cagct agctt gcttg cttgg ttggt tggtt ggttg gttgc ttgct tgctg gctgc ctgcc tgcca gccac ccact cactc actct ctctg tctgt ctgtt tgttg gttga ttgaa tgaag gaagc aagca agcag gcagc cagct agctg gctga ctgaa tgaaa gaaag aaaga aagaa agaag gaagc aagcc agccc gccca cccaa ccaag caagt aagta agtac gtaca tacag acagt cagta agtat gtatc tatcc atcct tcctc cctct ctctc tctcc ctcca tccag ccaga cagac agaca gacat acatt cattt atttg tttgc ttgca tgcaa gcaat caatt aattg attgg ttggc tggca ggcat gcatg catgg atgga tggaa ggaag gaaga aagac agaca gacag acagc cagcc agccc gcccc ccccg cccga ccgat cgatt gattt attta tttac ttact tactg actgg ctggc tggct ggctg gctgc ctgct tgcta gctag ctaga tagaa agaaa gaaag aaagg aaggt aggtg ggtgg gtggc tggca ggcag gcaga cagat agatc gatca atcat tcata catat atatt tattg attgg ttgga tggaa ggaag gaagt aagtg agtga gtgaa tgaac gaaca aacat acatt catta attat ttatg tatga atgaa tgaag gaagt aagtc agtcc gtcct tcctt ccttt ctttt ttttt tttta tttaa ttaac taact aactc actct ctctg tctga ctgag tgagg gagga aggaa ggaag gaagg aaggc aggca ggcat gcatt cattc attca ttcag tcagg caggc aggct ggctc gctct ctctg tctgg ctgga tggat ggatg gatga atgaa tgaag gaagt aagtc agtca gtcat tcata catat atatt tattt atttt ttttc tttcc ttcct tcctt ccttg cttgg ttgga tggaa ggaaa gaaac aaact aactt actta cttat ttatg tatga atgac tgaca gacat acatt catta attac ttaca tacaa acaac caaca aacag acagt cagtt agttc gttcg ttcgt tcgtg cgtgc gtgct tgctt gcttc cttca ttcag tcagt cagta agtag gtagg taggt aggta ggtat gtatg tatgt atgta tgtat gtatt tattt attta tttaa ttaat taatt aattt atttc tttcc ttcca tccaa ccaag caagt aagta agtat gtata tatat atatt tattc attcg ttcgg tcgga cggaa ggaag gaaga aagaa agaac gaaca aacac acaca cacag acaga cagat agata gatag atagc tagcg agcgt gcgtg cgtgg gtggt tggtg ggtga gtgat tgatc gatct atctt tcttc cttct ttctc tctct ctctg tctgg ctgga tggag ggaga gagaa agaag gaagg aagga aggat ggatc gatca atcag tcaga cagat agatg gatga atgaa tgaac gaact aactt actta cttac ttacg tacgc acgca cgcag gcagg caggg agggt gggtt ggtta gttac ttaca tacat acata catat atata tatat atatt tattt atttt ttttc tttca ttcac tcaca cacaa acaag caagg aaggc aggct ggctc gctcc ctcct tcctt ccttc cttct ttctc tctcc ctcct tcctg cctga ctgaa tgaaa gaaaa aaaaa aaaag aaagc aagcc agccg gccga ccgag cgagg gagga aggag ggagg gagga aggag ggaga gagag agagt gagtg agtga gtgag tgaga gagag agagg gaggc aggct ggctt gcttc cttct ttctg tctga ctgag tgagg gaggg aggga gggaa ggaac gaact aactc actct ctcta tctat ctatt tattt atttg tttgt ttgtt tgttt gtttg tttga ttgat tgatg gatgt atgtt tgttc gttct ttctc tctcc ctccg tccgc ccgcg cgcgc gcgca cgcag gcaga cagat agatc gatcg atcga tcgaa cgaac gaact aacta actac ctact tactg actgc ctgct tgctg gctgc ctgcc tgccc gccca cccat ccatg catgg atggt tggtc ggtct gtctt tcttg cttga ttgaa tgaac gaact aactg actga ctgag tgaga gagag agagt gagtc agtcc gtccc tccca cccat ccatt cattt atttc tttct ttcta tctag ctaga tagat agatc gatca atcat tcatc catcg atcga tcgat cgatt gattt atttt ttttc tttct ttctt tcttc cttcc ttcct tccta cctat ctatt tatta attac ttact tactt acttg cttgt ttgtc tgtct gtctc tctct ctctg tctgc ctgcc tgcca gccac ccacc cacca accag ccaga cagaa agaaa gaaat aaatg aatga atgag tgaga gagaa agaat gaatt aattc attcc ttcca tccaa ccaaa caaag aaaga aagaa agaat gaatg aatgg atggg tggga gggat ggata gatag ataga tagaa agaaa gaaaa aaaaa aaaac aaaca aacat acatc catct atctc tctcc ctcct tcctg cctga ctgag tgaga gagag agaga gagag agaga gagac agacg gacgt acgtt cgttt gtttg tttga ttgag tgagg gagga aggat ggatt gattc attcc ttcca tccaa ccaat caatc aatct atctg tctga ctgat tgata gatac atacc taccc accca cccaa ccaaa caaag aaaga aagag agaga gagat agatt gattc attct ttctc tctct ctctg tctgg ctggc tggcg ggcga gcgac cgacc gacca accaa ccaaa caaaa aaaag aaaga aagaa agaag gaagc aagcc agcct gcctt ccttc cttca ttcag tcagt cagtg agtga gtgat tgatg gatgg atgga tggaa ggaat gaata aataa ataac taact aactt acttc cttca ttcag tcagt cagtt agtta gttaa ttaag taaga aagaa agaat gaatt aattc attcc ttcct tcctg cctgg ctggt tggtt ggttt gttta tttaa ttaag taaga aagat agatt gattt atttt tttta tttac ttaca tacag acagg cagga aggaa ggaat gaata aatac atacg tacgt acgtt cgttg gttga ttgaa tgaac gaaca aacat acatc catca atcag tcagg caggt aggtt ggttg gttga ttgat tgatg gatga atgat tgatg gatgc atgca tgcaa gcaat caatg aatga atgat tgatg gatgg atggc tggca ggcaa gcaaa caaat aaatg aatgc atgca tgcag gcagc cagcc agccc gccca cccag ccaga cagaa agaaa gaaat aaatt aattt atttc tttcc ttccc tccct ccctt ccttc cttca ttcaa tcaat caata aatac atact tactc actcc ctcct tccta cctaa ctaaa taaaa aaaac aaacc aacca accaa ccaaa caaag aaaga aagaa agaag gaagg aagga aggat ggata gatat atatt tatta attac ttact tacta actac ctacc taccg accgt ccgtc cgtca gtcaa tcaag caagt aagtc agtct gtctt tcttt ctttg tttga ttgaa tgaac gaacg aacgc acgcc cgcca gccat ccatt catta attac ttacc taccc accca cccag ccagg caggc aggcc ggccg gccgg ccggg cgggc gggct ggctg gctga ctgac tgact gactg actgg ctggc tggct ggctg gctga ctgag tgagc gagcc agcca gccat ccatt catta attac ttact tactg actgg ctgga tggat ggatg gatgc atgcc tgccc gccca cccaa ccaag caagt aagtg agtgg gtgga tggat ggatc gatca atcaa tcaat caatg aatgc atgcc tgcca gccac ccact cactg actga ctgac tgacc gaccc accct ccctt ccttc cttct ttctg tctgc ctgcc tgccc gcccg cccgc ccgca cgcac gcacg cacgc acgct cgctg gctga ctgac tgacc gaccc accca cccac ccact cacta actac ctaca tacaa acaag caagt aagtc agtca gtcag tcagc cagct agctg gctgt ctgtc tgtca gtcaa tcaaa caaag aaagc aagct agctt gctta cttag\n"
     ]
    }
   ],
   "source": [
    "print(human_texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will perform the same steps for chimpanzee and dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_texts = list(chimp_data['words'])\n",
    "for item in range(len(chimp_texts)):\n",
    "    chimp_texts[item] = ' '.join(chimp_texts[item])\n",
    "y_chimp = chimp_data.iloc[:, 0].values                       # y_c for chimp\n",
    "\n",
    "dog_texts = list(dog_data['words'])\n",
    "for item in range(len(dog_texts)):\n",
    "    dog_texts[item] = ' '.join(dog_texts[item])\n",
    "y_dog = dog_data.iloc[:, 0].values   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will apply the BAG of WORDS using CountVectorizer using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model using CountVectorizer()\n",
    "# This is equivalent to k-mer counting\n",
    "# The n-gram size of 4 was previously determined by testing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(4,4))\n",
    "X = cv.fit_transform(human_texts)\n",
    "X_chimp = cv.transform(chimp_texts)\n",
    "X_dog = cv.transform(dog_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 65447)\n",
      "(1682, 65447)\n",
      "(820, 65447)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_chimp.shape)\n",
    "print(X_dog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have a look at class balance we can see we have relatively balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b7b69e9f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_data['class'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the human dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y_data, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 65447)\n",
      "(876, 65447)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A multinomial naive Bayes classifier will be created.  I previously did some parameter tuning and found the ngram size of 4 (reflected in the Countvectorizer() instance) and a model alpha of 0.1 did the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Multinomial Naive Bayes Classifier ###\n",
    "# The alpha parameter was determined by grid search previously\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, so let's look at some model performce metrics like the confusion matrix, accuracy, precision, recall and f1 score.  We are getting really good results on our unseen data, so it looks like our model did not overfit to the training data.  In a real project I would go back and sample many more train test splits since we have a relatively small data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "Predicted   0   1   2    3    4   5    6\n",
      "Actual                                  \n",
      "0          97   0   0    0    4   0    1\n",
      "1           5  92   0    1    3   0    5\n",
      "2           0   0  77    0    1   0    0\n",
      "3           0   0   0  122    2   0    1\n",
      "4           2   0   0    0  143   0    4\n",
      "5           0   0   0    0    0  48    3\n",
      "6           2   1   0    3    1   1  257\n",
      "accuracy = 0.954 \n",
      "precision = 0.955 \n",
      "recall = 0.954 \n",
      "f1 = 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
